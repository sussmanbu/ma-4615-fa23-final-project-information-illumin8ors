[
  {
    "objectID": "blog4 code.html",
    "href": "blog4 code.html",
    "title": "blog 4 :code",
    "section": "",
    "text": "load(“C:/Users/73113/Downloads/NSDUH-2021-DS0001-bndl-data-r_v3/NSDUH_2021.RData”) library(tidyverse) library(readr) drug_health_data_clean_new &lt;- PUF2021_100622 |&gt; select(QUESTID2, filedate, cigwilyr,cigtry,cigrec,CIG30AV, alctry, alcrec, aldaypwk, ALCUS30D, AL30EST, mjage, mjrec, mrdaypwk, MJDAY30A, MR30EST, cocage, cocrec, ccdaypwk, CC30EST, crkage, crdaypwk, crakrec, CR30EST, herage, herrec, hrdaypwk, HR30EST, hallucage, hallucrec, halldypwk, HALLUC30E, lsdage, pcpage, ecstmoage, inhalage, inhalrec, inhdypwk, INHAL30ES, methamage, methamrec, methdypwk, METHAM30E, oxcnanyyr, oxcnnmage, fentanyyr, pnranyrec, PNRNM30ES, PNRNM30AL, pnrwygamt, pnrwygamt, pnrwyoftn, pnrwylngr, trqanylif, trqanyrec, stmanylif, stmanyrec, sedanylif, sedanyrec, iicigrc, II2CIGRC, iralcrc, II2ALCRC, iicrkrc, II2CRKRC, alcyrtot, cocyrtot, crkyrtot, heryrtot, hallucyfq, methamyfq, ircigfm, ircgrfm, IRSMKLSS30N, iralcfm, irmjfm, ircocfm, ircrkfm, cigflag, cigyr, cigmon, cgrflag, cgryr, cgrmon, pipflag, pipmon, smklssflag, smklssyr, smklssmon, tobflag, tobyr, tobmon, AD_MDEA1,AD_MDEA2, AD_MDEA3, AD_MDEA4, yther, yshsw, YUMHTELYR2, yowrslow, yowrdcsn, YO_MDEA1, YO_MDEA2, YO_MDEA3, YO_MDEA4, YO_MDEA5, YO_MDEA6, YO_MDEA7, YO_MDEA8, yopsrels, ymdelt, cadrpeop, casurcvr, camhprob, vapanyevr, irvapanyrec, CAMHPROB2, vaptypemon, udaltimeget, udaltrystop, udalstopact, udalwdsweat, udalavwsvtr, udmjtimeget, udmjlesseff, udmjnotstop, udmjwddeprs, udcctimeget, udccwantbad, udccstrurge, udccstopact, udhetimeuse, udhenotstop,udhehlthprb, udhestopact, udhatimeuse, booked, bkdrvinf, txevrrcvd, txyrprisn, txyrslfhp, txltpyhins, snysell, snyattak, snrldcsn, yeatndyr, yehmslyr, yestscig, DSTNRV30, suiplanyr, irmedicr, irmcdchp, irchmpus, irchmpus, irprvhlt, irothhlt, irfamsoc, irfamssi, irfstamp, irfampmt, IRPINC3, IRFAMIN3, PDEN10, COUTYP4, MAIIN102, AIIND102, ENRLCOLLFT2, wrkhadjob, sexident, milstat, NEWRACE2, income, POVERTY3, PDEN10, COUTYP4) |&gt; mutate(NEWRACE2 = recode(NEWRACE2, “1” = “NonHisp White”, “2” = “NonHisp Black/Afr Am”, “3” = “NonHisp Native Am/AK Native”, “4” = “NonHisp Native HI/Other Pac Isl”, “5” = “NonHisp Asian”, “6” = “NonHisp more than one race”, “7” = “Hispanic”))\nsummary_by_race &lt;- drug_health_data_clean_new %&gt;% filter(MJDAY30A &lt;= 30) %&gt;% group_by(NEWRACE2) %&gt;% summarise( Mean_MJDAY30A = mean(MJDAY30A, na.rm = TRUE), Median_MJDAY30A = median(MJDAY30A, na.rm = TRUE), Max_MJDAY30A = max(MJDAY30A, na.rm = TRUE), Min_MJDAY30A = min(MJDAY30A, na.rm = TRUE) ) ggplot(summary_by_race, aes(x = NEWRACE2, y = Mean_MJDAY30A, fill = NEWRACE2)) + geom_bar(stat = “identity”) + labs(title = “Mean Marijuana Use in the Last 30 Days by Race”, x = “Race”, y = “Mean Days of Marijuana Use”) + theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.position = “none”) + coord_cartesian(ylim = c(1, 30))\nglm_model &lt;- glm(MJDAY30A ~ NEWRACE2, data = drug_health_data_clean_new, family = poisson(link = “log”))"
  },
  {
    "objectID": "posts/2023-11-13-blog-post-4-/blog-post-4-.html",
    "href": "posts/2023-11-13-blog-post-4-/blog-post-4-.html",
    "title": "Blog Post 4",
    "section": "",
    "text": "This is a plot that shows the ages that people first used cocaine and the plot is faceted by race. On the y-axis, the frequency tells us the number of survey takers that had the same response. This tells us that people in the “NonHisp White” category had the highest number of people who had ever used cocaine, and there is a common trend across all race categories that the most typical age range when cocaine was first used was between 10 and 30 years old. This result is informative, but it also raised a concern because it made us think that the number of respondents per race category was possibly skewed and led us to question how many survey takers fit into each race category.\n\n\n\n\nThe boxplot titled “TOTAL # OF DAYS USED ALCOHOL IN PAST 12 MOS by RACE (Excluding &gt;365 days)” visually represents the distribution of the total number of days alcohol was used in the past 12 months across different racial groups. This visualization is particularly useful for understanding the central tendency, variability, and presence of outliers in the data. In detail, the Asian category shows a slightly lower median compared to others, suggesting a marginally lesser median frequency of alcohol use within this group over the period. Notably, the White category exhibits the largest box, indicating greater variability or dispersion in alcohol use days among individuals in this group. Moreover, in this plot, the Hispanic and Black categories show more outliers on the higher end of the spectrum. This suggests that there are more instances of significantly higher alcohol use days in these groups compared to the typical range observed within the groups.\n\n\n\n \nThis logistic regression model shows many things that can be broken down into understanding. First the intercept used for this model was the Hispanic population and this is due to the dataset being split into Non Hispanic and Hispanic so using the Hispanic population as a baseline was easier for analysis. The coefficient for the intercept/Hispanic population shows that when all other variables are being held constant, the log odds for Hispanic population is -0.70059. This is just in a sense the baseline to compare to the other races. For the Asian population of this dataset, when converting the log odds to odd ratio, the odds of an Asian population smoking cigarettes is 0.6482 times the odds of Hispanics smoking cigarettes. This means that the odds of the Asian population smoking cigarettes is lower than the Hispanic population. This can be seen for any values less than 1 for race categories but we see a change once we get to Non Hispanics that are more than one race where they are greater than 1 odd ratios meaning they have a higher odd ratio of smoking cigarettes compared to Hispanics. The White race group has the highest odd ratio compared to Hispanics and other groups, making them more likely to smoke cigarettes than Hispanic people. In terms of the numbers from the model, White people in the dataset have 1.9676 times the odds of smoking cigarettes compared to Hispanics.\nThis model works and fits for this dataset because the p values for each of the variables of races are lower than 0.05 showing they have significant value. The model also predicts that cigarette use and race groups have a significant relationship based on the amount of stars placed on each row, showing an emphasis on the relationship between the two. It suggests that there are differences in race groups for cigarette smoking trying it for the first time which can be explored further with data either from the outside or other variables that might have relationships with it such as income or geographic location.\nThese are some of the simple relationships we were able to notice upon EDA. Exploring these further is crucial in making key conclusions and hypothesis."
  },
  {
    "objectID": "posts/2023-11-13-blog-post-4-/blog-post-4-.html#a-look-into-the-relationships-eda",
    "href": "posts/2023-11-13-blog-post-4-/blog-post-4-.html#a-look-into-the-relationships-eda",
    "title": "Blog Post 4",
    "section": "",
    "text": "This is a plot that shows the ages that people first used cocaine and the plot is faceted by race. On the y-axis, the frequency tells us the number of survey takers that had the same response. This tells us that people in the “NonHisp White” category had the highest number of people who had ever used cocaine, and there is a common trend across all race categories that the most typical age range when cocaine was first used was between 10 and 30 years old. This result is informative, but it also raised a concern because it made us think that the number of respondents per race category was possibly skewed and led us to question how many survey takers fit into each race category.\n\n\n\n\nThe boxplot titled “TOTAL # OF DAYS USED ALCOHOL IN PAST 12 MOS by RACE (Excluding &gt;365 days)” visually represents the distribution of the total number of days alcohol was used in the past 12 months across different racial groups. This visualization is particularly useful for understanding the central tendency, variability, and presence of outliers in the data. In detail, the Asian category shows a slightly lower median compared to others, suggesting a marginally lesser median frequency of alcohol use within this group over the period. Notably, the White category exhibits the largest box, indicating greater variability or dispersion in alcohol use days among individuals in this group. Moreover, in this plot, the Hispanic and Black categories show more outliers on the higher end of the spectrum. This suggests that there are more instances of significantly higher alcohol use days in these groups compared to the typical range observed within the groups.\n\n\n\n \nThis logistic regression model shows many things that can be broken down into understanding. First the intercept used for this model was the Hispanic population and this is due to the dataset being split into Non Hispanic and Hispanic so using the Hispanic population as a baseline was easier for analysis. The coefficient for the intercept/Hispanic population shows that when all other variables are being held constant, the log odds for Hispanic population is -0.70059. This is just in a sense the baseline to compare to the other races. For the Asian population of this dataset, when converting the log odds to odd ratio, the odds of an Asian population smoking cigarettes is 0.6482 times the odds of Hispanics smoking cigarettes. This means that the odds of the Asian population smoking cigarettes is lower than the Hispanic population. This can be seen for any values less than 1 for race categories but we see a change once we get to Non Hispanics that are more than one race where they are greater than 1 odd ratios meaning they have a higher odd ratio of smoking cigarettes compared to Hispanics. The White race group has the highest odd ratio compared to Hispanics and other groups, making them more likely to smoke cigarettes than Hispanic people. In terms of the numbers from the model, White people in the dataset have 1.9676 times the odds of smoking cigarettes compared to Hispanics.\nThis model works and fits for this dataset because the p values for each of the variables of races are lower than 0.05 showing they have significant value. The model also predicts that cigarette use and race groups have a significant relationship based on the amount of stars placed on each row, showing an emphasis on the relationship between the two. It suggests that there are differences in race groups for cigarette smoking trying it for the first time which can be explored further with data either from the outside or other variables that might have relationships with it such as income or geographic location.\nThese are some of the simple relationships we were able to notice upon EDA. Exploring these further is crucial in making key conclusions and hypothesis."
  },
  {
    "objectID": "posts/2023-11-20-blog-post-5/blog-post-5.html",
    "href": "posts/2023-11-20-blog-post-5/blog-post-5.html",
    "title": "Blog Post 5",
    "section": "",
    "text": "To find appropriate data sets that would align with our data, we had to first look into how the location data was collected. The public access data file for the SAMHSA NSDUH 2021 has somewhat limited geographic information, but we have come up with some creative ways to exploit what is there. They provide a variable, “PDEN10”, with information about population density, telling us how many respondents live in a CBSA with 1 million or more people, less than 1 million people, or not in a CBSA, where CBSA stands for “Core-based statistical area”. This variable also uses 2010 census data. To expand upon this variable, we have downloaded data sets from the 2009 CBSA and the 2010 census, which match the data that the original researchers used in the survey. Our plan is to combine the census and CBSA codes, we will divide the census data set by filtering for counties with 1 million and less than 1 million inhabitants, then we will match those with CBSA codes and group/match the survey answers to those counties/CBSA codes. We will group all counties with no CBSA code into an “other” category.\nAnother variable of interest is the “COUNTYP4” column, which describes how many people are in large, small, or non-metro areas. This variable is based on 2013 Rural/Urban continuum codes. We have found that dataset and we will be using it to break down the counties that are classified as large, small, or non-metro to provide further information about which counties and states the respondents of the data set come from. These are the two most general variables concerning location information, but there are others that use the 2010 census data to describe how many people taking the survey live in an American-Indian census block or not. Thus we can also use the 2010 census data set to discover where those areas are to better inform our geographic data.\nThrough such integration, we can establish a more comprehensive, multidimensional dataset, providing a deeper background for our analysis. The selection and integration of these datasets will enable us to explore patterns of drug and substance abuse from various perspectives, gaining a more comprehensive understanding of this issue under the influence of geographical and demographic factors."
  },
  {
    "objectID": "posts/2023-11-20-blog-post-5/blog-post-5.html#understanding-the-datasets",
    "href": "posts/2023-11-20-blog-post-5/blog-post-5.html#understanding-the-datasets",
    "title": "Blog Post 5",
    "section": "",
    "text": "To find appropriate data sets that would align with our data, we had to first look into how the location data was collected. The public access data file for the SAMHSA NSDUH 2021 has somewhat limited geographic information, but we have come up with some creative ways to exploit what is there. They provide a variable, “PDEN10”, with information about population density, telling us how many respondents live in a CBSA with 1 million or more people, less than 1 million people, or not in a CBSA, where CBSA stands for “Core-based statistical area”. This variable also uses 2010 census data. To expand upon this variable, we have downloaded data sets from the 2009 CBSA and the 2010 census, which match the data that the original researchers used in the survey. Our plan is to combine the census and CBSA codes, we will divide the census data set by filtering for counties with 1 million and less than 1 million inhabitants, then we will match those with CBSA codes and group/match the survey answers to those counties/CBSA codes. We will group all counties with no CBSA code into an “other” category.\nAnother variable of interest is the “COUNTYP4” column, which describes how many people are in large, small, or non-metro areas. This variable is based on 2013 Rural/Urban continuum codes. We have found that dataset and we will be using it to break down the counties that are classified as large, small, or non-metro to provide further information about which counties and states the respondents of the data set come from. These are the two most general variables concerning location information, but there are others that use the 2010 census data to describe how many people taking the survey live in an American-Indian census block or not. Thus we can also use the 2010 census data set to discover where those areas are to better inform our geographic data.\nThrough such integration, we can establish a more comprehensive, multidimensional dataset, providing a deeper background for our analysis. The selection and integration of these datasets will enable us to explore patterns of drug and substance abuse from various perspectives, gaining a more comprehensive understanding of this issue under the influence of geographical and demographic factors."
  },
  {
    "objectID": "posts/2023-11-20-blog-post-5/blog-post-5.html#process-and-next-steps",
    "href": "posts/2023-11-20-blog-post-5/blog-post-5.html#process-and-next-steps",
    "title": "Blog Post 5",
    "section": "Process and Next Steps",
    "text": "Process and Next Steps\nWe did not combine the data yet as we are viewing it first individually and then we will combine the data. We do not expect any difficulties with combining it because we can use the RUCC and the CBSA with the census data to get a better understanding of the metro data from the NSDUH data. The process to join the data is to first take the RUCC and associate it with the names of counties in the United States. Then using the CBSA and the census data, we can associate the CBSA with an area in the United States, giving us access to census population which is correlated to the NSDUH calculation of population metric for respondents and where they can be from. This gives us a deeper understanding of where respondents are most likely to be from based off of CBSA and Census data and whether they are from large or small cities based on RUCC as well.\nAlthough we have not yet been able to sufficiently combine the location data sets from the CBSA, RUCC, and Census, our next steps will be to finish cleaning the data sets and then filter the populations by county and likely make a map of the population densities using the geom_sf() tool within ggplot to better show where the survey respondents are located. We will also want to make a table and probably pivot the data to expand the given columns with location/population information to give more information about the possible counties the respondent could come from.\nFor these data sets we would be to combine and then create relationships between drug use and certain large metros that can be correlated with the population of such top metros. This data gives us the best approximation of where respondents may be from and also gives correlations for how these large or small metros and also CBSA codes with the counties census can be seen with drug related problems. We want to take our analysis even further and hopefully use some models that can help give a deeper understanding of what is going on with such respondent info. We also want to explore more relationships between certain variables in the NSDUH dataset and see if we can use such relationships to go even deeper into how location plays a role in affecting such relationships. Exploring this further is crucial in understanding drug and substance abuse."
  },
  {
    "objectID": "posts/2023-10-30-blog-post-2/blog-post-2.html",
    "href": "posts/2023-10-30-blog-post-2/blog-post-2.html",
    "title": "Blog Post 2",
    "section": "",
    "text": "The principles emphasize the importance of considering the impact of data collection, analysis, and dissemination on the communities and individuals being studied. While our data analysis may not directly involve community interaction, we can apply these principles by ensuring that the data we use are collected and analyzed in a way that respects the principles of beneficence, respect for persons, and justice. This includes considering the potential benefits and harms of the data, being transparent about the data’s limitations, and striving for a fair distribution of burdens and benefits.\nSince we are not the ones actually collecting the data, we cannot really consider the principles in relation to that beyond choosing data sets from reputable and ethical sources, but we can think about the principles in their relation to data cleaning, visualization, and analysis. For example, we want to make sure we ask interesting but respectful/considerate questions for our analysis. We also want to make sure, while cleaning the data, that we do eliminate data that is relevant to the groups we are looking at, we do not want to be biased in cleaning our data because we want to keep our analysis representative of the survey participants. Adding on, being able to fairly assess and understand what the data is representing is key to not misinterpret and fall short in analysis. Transparency is key for the audience to understand how the data is being collected and shown so that misinterpretations can be minimized to the best possible degree.\nThe principles of equitable data practice discussed in the article are: beneficence, justice, and respect for persons. When looking at our data set, we have to make sure that there is data available for a diverse range of different demographics. This idea ties into the justice principle because we want to make sure that our data represents multiple perspectives and communities. While our data includes data on income, age, health insurance, and race, it lacks detailed information on the location of the respondents. It would be good to supplement our data with another data set that gives us information about the general location demographics of the participants. Then, beneficence comes in because we want to be aware how sensitive topics can affect certain groups. Since our data concerns substance abuse and mental health disorders, we have to be sensitive when looking at the data and with the questions we decide to ask about it.\nAdhering to the practice of transparency would entail providing clear and comprehensive information about the data, including its limitations and potential sources of bias. It would involve documenting the data collection and analysis processes, making sure the data’s context is well-understood, and acknowledging any potential misinterpretations or misuses of the data. Additionally, the principle of respect for persons would require obtaining informed consent when necessary and protecting the privacy of individuals whose data is used. This helps in maintaining respect amongst individuals for their data collected and also having privacy concerns lowered so that individuals do not fear their data is being used for the wrong purposes.\nIn our analysis, it is possible that due to limited sample size, we were unable to collect a certain amount of data for each race. To address this, we could filter the data set to make sure we are analyzing a comparable amount of data for each race category to make sure we are not biasing the data or producing false data analysis. At the same time, the data itself may have limitations due to the fact that the respondents who can be contacted have similar identities to the investigators. In terms of potential abuse or misuse, if the data is not adequately protected, it could be accessed or used in ways that harm individuals or communities.\nThere might be sampling bias. If the data is not representative of the entire population, conclusions drawn from it might not be generalizable. For instance, certain demographics might be underrepresented or over represented. Moreover, data related to substance use often relies on self-reporting, which can be subject to recall bias and social desirability bias. If not handled carefully, data on substance use can contribute to the stigmatization of individuals who use or have used substances, potentially leading to discrimination or other negative outcomes. Furthermore, Without proper context or understanding, the data can be misinterpreted. For example, high rates of substance use in a particular demographic might be wrongly attributed to cultural or inherent factors rather than socio-economic or environmental reasons. This can further cause divides and lead back to the topic of misinterpretation which hinder from the point that we as a group are trying to convey in our reports and plots."
  },
  {
    "objectID": "posts/2023-12-11-blog-post-7/blog-post-7.html",
    "href": "posts/2023-12-11-blog-post-7/blog-post-7.html",
    "title": "Blog Post 7",
    "section": "",
    "text": "Some main questions we have been trying to answer are: What are the key factors that play into a person’s tendency to use substances? How large of a factor is race? Is race or income a better predictor of substance use? Do large, small, or non-metro areas use more substances? Do mental health and/or education have a larger effect than any of the previously mentioned factors?\nWe have kept these questions in mind when constructing our thesis. A current working thesis is: There are many factors that play into substance use, including but not limited to race, income, location, and mental health; however, race is one of the most important factors, and there is a clear relationship that shows certain races tend to use more substances than others.\nTo support this thesis, we have done a logistical regression to investigate and visualize the relationship between substance use and race and it was clear that there is a strong enough correlation to draw conclusions. To explore other factors that influence drug use and to as a result strengthen the relationship between drug use and race, we will include linear models that, when compared, will show us whether race, income, or mental health is a better predictor of substance use. Furthermore, it is important to ensure the validity after building these linear models. For example, using the statistical tests and evaluating the AIC or BIC to find out the accuracy of the model, careful interpretation is also needed."
  },
  {
    "objectID": "posts/2023-12-11-blog-post-7/blog-post-7.html#tentative-thesis-continued",
    "href": "posts/2023-12-11-blog-post-7/blog-post-7.html#tentative-thesis-continued",
    "title": "Blog Post 7",
    "section": "",
    "text": "Some main questions we have been trying to answer are: What are the key factors that play into a person’s tendency to use substances? How large of a factor is race? Is race or income a better predictor of substance use? Do large, small, or non-metro areas use more substances? Do mental health and/or education have a larger effect than any of the previously mentioned factors?\nWe have kept these questions in mind when constructing our thesis. A current working thesis is: There are many factors that play into substance use, including but not limited to race, income, location, and mental health; however, race is one of the most important factors, and there is a clear relationship that shows certain races tend to use more substances than others.\nTo support this thesis, we have done a logistical regression to investigate and visualize the relationship between substance use and race and it was clear that there is a strong enough correlation to draw conclusions. To explore other factors that influence drug use and to as a result strengthen the relationship between drug use and race, we will include linear models that, when compared, will show us whether race, income, or mental health is a better predictor of substance use. Furthermore, it is important to ensure the validity after building these linear models. For example, using the statistical tests and evaluating the AIC or BIC to find out the accuracy of the model, careful interpretation is also needed."
  },
  {
    "objectID": "posts/2023-12-11-blog-post-7/blog-post-7.html#polishing-and-wrapping-up",
    "href": "posts/2023-12-11-blog-post-7/blog-post-7.html#polishing-and-wrapping-up",
    "title": "Blog Post 7",
    "section": "Polishing and Wrapping Up",
    "text": "Polishing and Wrapping Up\nWe will make sure to include titles that explain the variables we are plotting. We will also include appropriately labeled axes and figure legends. In the figure legends under each figure, we will briefly describe how the plot was made, why it was made, and what conclusions can be drawn. To keep everything cohesive, we have discussed using theme_minimal() which would keep the data visuals from looking cluttered. We have also carefully thought about the order in which the figures should be included on our website so that anyone reading through it would be able to follow. By this we mean that we want the knowledge gained by each figure to build on each other, starting basic and then building into relationships displaying more complex relationships between variables so that the reader could easily keep track of our thought process and how we have supported our thesis.\nWe also plan to ensure the order in which we present the plots in the analysis page and the big picture page are greatly placed. We are in the process of including relevant images and information for the finished product and making it flow easier from one page to the next. Order is a key aspect which is focused on so that the viewer can understand everything in a manner that isn’t fast paced and well ordered. Wrapping everything up is key in making our project look visually appealing while also displaying the message and thesis to our audience."
  },
  {
    "objectID": "posts/2023-12-04-blog-post-6/blog-post-6.html",
    "href": "posts/2023-12-04-blog-post-6/blog-post-6.html",
    "title": "Blog Post 6",
    "section": "",
    "text": "We have uploaded excel files containing 2010 census information and 2009 CBSA codes, which the original survey makers/data collectors used to process location data information. We are working on merging the two right now to compare them to our existing data set. We have identified the counties/areas that appear both in the Census and CBSA data set. The next goal is to merge the census and CBSA data sets by lining up the information about each overlapping county so that we can get population totals for metro and non-metro areas since that is how location data is categorized in our data set. We know how many respondents come from metro versus non-metro areas, but now we will be able to guess at which counties those individuals come from. It will be interesting, once this is done, to use the geom_sf() function to visualize the spread and density of respondents by US geographical area and then to potentially use this to graph which areas have highest drug or alcohol use.\nWe have also explored multiple drugs and their relations to race and much can be seen about the relationships between the two. We are working on furthering this plot even further to depict the relationship between them better. Working on the Race vs Income predictor using linear regression model is also something we have explored because understanding a key relationship between these two variables help with the thesis and how we can support it and also explore the pitfalls of it. For instance, in the linear regression model, by encoding the race as a categorical variable and setting the income as the dependent variable, we would get the information given from this model. Then we could start model checking for further analysis like addressing Pitfalls. By finding the high correlation between these variables and addressing some issues, we would enhance the validity of our findings. One thing we have noticed about our dataset that limits us is how the survey was set up in that a respondent does not give a number for income but a range which hurts in creating unique values but we are able to make arrangements to go around this issue. We were really interested also in finding out more about how the data was being weighted based on how many people from each race responded to the survey. This is key in understanding more about the survey because it helps determine the representation of this dataset as well which can help with understanding our accuracy for the results given from plots and models.\nWe are looking forward to wrapping the EDA portion of the project by attaining models and plots that really highlight what we are trying to tell to the public about the relationship between race and drug use. Hitting many dead ends as we were doing this project was something we had to overcome because sometimes the questions were skipped by respondents but we were able to find other questions that aligned with what we wanted to use that had more responses. Being able to explain these plots and models is super important and we will use the plots to help showcase and break down the relationships found into elementary parts.\nSome evidence that has already started to present itself is a logistic model created to show cigarette use and race and showing a simple difference between races in how many try cigarettes and use them. Simple models like this can help us go further in understanding whether location play a role in this difference or is it an income difference. Further exploration shows that both do in fact play a role. Whether a person is in a large metro or small metro or rural area is a big factor in what person does in terms of drug related options. Income is also a major factor in what is shown for drug use in that a person with higher income may tend to use more expensive drugs or certain types of drugs and this statement definitely has problems with it as well. Race can be associated with this and the location of whether it is a big city or not is seen to play a role in such a relationship. Being able to plot these relationships effectively is important in letting the general public and those interested in knowing more about this in effectively understanding the relationships."
  },
  {
    "objectID": "posts/2023-12-04-blog-post-6/blog-post-6.html#eda",
    "href": "posts/2023-12-04-blog-post-6/blog-post-6.html#eda",
    "title": "Blog Post 6",
    "section": "",
    "text": "We have uploaded excel files containing 2010 census information and 2009 CBSA codes, which the original survey makers/data collectors used to process location data information. We are working on merging the two right now to compare them to our existing data set. We have identified the counties/areas that appear both in the Census and CBSA data set. The next goal is to merge the census and CBSA data sets by lining up the information about each overlapping county so that we can get population totals for metro and non-metro areas since that is how location data is categorized in our data set. We know how many respondents come from metro versus non-metro areas, but now we will be able to guess at which counties those individuals come from. It will be interesting, once this is done, to use the geom_sf() function to visualize the spread and density of respondents by US geographical area and then to potentially use this to graph which areas have highest drug or alcohol use.\nWe have also explored multiple drugs and their relations to race and much can be seen about the relationships between the two. We are working on furthering this plot even further to depict the relationship between them better. Working on the Race vs Income predictor using linear regression model is also something we have explored because understanding a key relationship between these two variables help with the thesis and how we can support it and also explore the pitfalls of it. For instance, in the linear regression model, by encoding the race as a categorical variable and setting the income as the dependent variable, we would get the information given from this model. Then we could start model checking for further analysis like addressing Pitfalls. By finding the high correlation between these variables and addressing some issues, we would enhance the validity of our findings. One thing we have noticed about our dataset that limits us is how the survey was set up in that a respondent does not give a number for income but a range which hurts in creating unique values but we are able to make arrangements to go around this issue. We were really interested also in finding out more about how the data was being weighted based on how many people from each race responded to the survey. This is key in understanding more about the survey because it helps determine the representation of this dataset as well which can help with understanding our accuracy for the results given from plots and models.\nWe are looking forward to wrapping the EDA portion of the project by attaining models and plots that really highlight what we are trying to tell to the public about the relationship between race and drug use. Hitting many dead ends as we were doing this project was something we had to overcome because sometimes the questions were skipped by respondents but we were able to find other questions that aligned with what we wanted to use that had more responses. Being able to explain these plots and models is super important and we will use the plots to help showcase and break down the relationships found into elementary parts.\nSome evidence that has already started to present itself is a logistic model created to show cigarette use and race and showing a simple difference between races in how many try cigarettes and use them. Simple models like this can help us go further in understanding whether location play a role in this difference or is it an income difference. Further exploration shows that both do in fact play a role. Whether a person is in a large metro or small metro or rural area is a big factor in what person does in terms of drug related options. Income is also a major factor in what is shown for drug use in that a person with higher income may tend to use more expensive drugs or certain types of drugs and this statement definitely has problems with it as well. Race can be associated with this and the location of whether it is a big city or not is seen to play a role in such a relationship. Being able to plot these relationships effectively is important in letting the general public and those interested in knowing more about this in effectively understanding the relationships."
  },
  {
    "objectID": "posts/2023-12-04-blog-post-6/blog-post-6.html#tentative-thesis",
    "href": "posts/2023-12-04-blog-post-6/blog-post-6.html#tentative-thesis",
    "title": "Blog Post 6",
    "section": "Tentative Thesis",
    "text": "Tentative Thesis\nOur tentative thesis is something along the lines of certain races tend to try or use drugs more than other races. Certain cities/rural areas have more or less drug use for certain races. A higher income could have more drug use or low income could have more drug use. We believe a strong and clear thesis from the data analysis we did because it explores important aspects in society that are not presented in the best manner to the public and understanding these differences can help with allocating resources towards those who need help and understanding where drug related problems can occur. Understanding the potential causes can help with addressing such causes as a public or through government. This thesis is still a draft and will be refined more as the EDA wraps up. We plan on making it more refined of a thesis towards the end that fully encompasses our exploration of the data."
  },
  {
    "objectID": "posts/2023-11-06-blog-post-3/blog-post-3.html",
    "href": "posts/2023-11-06-blog-post-3/blog-post-3.html",
    "title": "Blog Post 3",
    "section": "",
    "text": "To approach the data in a way such that we can do efficient cleaning but also have the columns and rows we need to accurately assess the data, we first needed to understand what was recorded from the dataset. Once we understood that we divided and conquered the codebook associated with this data from the SAMHSA. We needed to look at questions answered in the survey such that they had a high response rate and also that they would be able to help in further analysis as well. We are focusing more on cutting many unnecessary columns that would not be as used throughout but also columns that tend to have high no response rates as well. This strategy is effective for the beginning as it gives a very good sense with what we are working with.\nSome of the important columns we needed were which types of drugs people had tried and certain questions like if they have used in the past 30 days. We were also interested in the columns that reported on the age when a person used a substance because we could make an interesting comparison between ages a substance was first used by race. Then we also made sure to include questions about mental health and whether each respondent went out to receive treatment for mental health. This data could allow us to look at relationships between race, mental health treatment, and drug use. Other columns that were important are ones that discuss location as this will relate what we need if we need other datasets to incorporate into it with more precise location . Relating mental health with location as well as drug use to location can help with economic datasets per location be used as well as a follow up to further support the dataset and create more analysis. Another interesting comparison would be to look at the relationship between age of first use of a substance by race to see if there is a good trend/comparison there.\nNot only was this the thinking of our group for the data cleaning strategy, we also quickly realized how important it is to look at certain outliers and data points that might not work for analysis. One of the important points mentioned before was high non response rates which we quickly saw through in the table that we filtered for just cigarettes to understand how much is really missing. The codebook also helps in understanding this as well. This can be quickly seen through a look at the table with all the columns pictured below in the table sample: \nQuickly looking into just this little sample shows that the cigyfu column has a bunch of skipped answers based on the codebook notation as well to support this. The 9999 and 99 and 991 are all variations of “NA” or did not want to respond to the survey to such a particular question as indicated by the codebook. As we continue to go through the data set we will be cautious to check for outliers."
  },
  {
    "objectID": "posts/2023-10-23-blog-post-1/blog-post-1.html",
    "href": "posts/2023-10-23-blog-post-1/blog-post-1.html",
    "title": "Blog Post 1 - Datasets Search",
    "section": "",
    "text": "We were very invested in taking the route of exploring racial disparity with drug use, income and mental illness and felt these datasets below represent the topic we are interested in very well.\nThe first dataset that we had found was within this link: “https://data.world/balexturner/drug-use-employment-work-absence-income-race-education”.This dataset is called “NSDUH Workforce Adults”. This dataset has 64 columns and 32,040 rows and is taken from the health survey conducted in 2015 by the Substance Abuse and Mental Health Services Administration. Since this is a subset selected it is supposed to be randomly selected for optimal analysis. Loading the data was easy as it was a csv easily loaded into R Studio. We have not started cleaning the dataset but we are able to parse through the dataset and get specific columns and data points we might need making it easier for us. The ease of loading it into R Studio and the ability to extract specific columns and data points make this dataset a promising resource for conducting a comprehensive exploration of various socio-economic and health-related factors among adult populations\nThe second dataset that we had found was within this link “https://www.icpsr.umich.edu/web/NACJD/studies/27521/variables”. The dataset is called “Gender, Mental Illness, and Crime in the United States, 2004”. This dataset has 3011 columns and for rows it has more than 2GB of data and the last row is 55,602. The data was collected from a 2004 survey on drug use and health to the public. The data is plentiful with data but however is not up to date with current date and the surveys were major revamped. There are columns that were added to this dataset by the researchers of this dataset. We were able to load the data and get the columns and be able to see some of the sample responses. The only problem with this dataset would be that it may be too old for use but it does contain information that would be useful for relating racial disparity, drug use and justice system.\nThe third dataset that we had found is “https://www.datafiles.samhsa.gov/dataset/national-survey-drug-use-and-health-2021-nsduh-2021-ds0001”. This dataset is straight from the SAMHSA (Substance Abuse and Mental Services Administration) which conducts surveys directly and collects and asks questions. There is an associated codebook for the data that can help us determine relationships between certain drugs and income and much more as well. Some of the collection methods were web-interviewing and more and cannot be compared at all to previous years according to the website, which offers the most up to date collection. This NSDUH dataset has 2,989 columns and 58,034 entries of rows. It has very big general population coverage in order to analyze. We were able to load the R data into R studio and convert it into a csv as well. Being able to parse the data was also fairly simple which helps in finding relationships between race and medical conditions and more. This is the dataset we are most excited for because of how fairly new it is and how many ways we can go about this topic with this many variables/questions.\nSince we have found three very expansive and diverse data sets, we know that there is a lot of potential for questions we can explore. In our first data set, from the NDSUH codebook linked above, there are several columns of interest to us. This data set covers race, income, and location in relation to drug and alcohol use. Thus we can ask questions such as: what is the link between race and lifetime drug or alcohol use? If we filter by lower income areas, is the link between race and drug/alcohol use stronger? Is income or race a more important influencing factor in drug/alcohol use? These questions can be addressed by the data we have found and we are excited to learn more about how to visualize the data to best address trends in our data. The data set from data.world is also a great option and it has several variables of interest to us. It provides links between drug use, employment rates, work absence, income, race, and education. This would allow us to ask questions such as: Is education level or employment rate by race a stronger influencing factor towards drug use? What is the variance of income by race? What is the average drug use by race and income level and which seems to have more of an influence on drug use? While this data set is interesting and useful, it does not allow us to ask complex questions such as what kind of drugs are more heavily used by different race categories and by different income levels, as the NDSUH codebook data set would allow us to do. The data set from UMich could also be good to use, it has interesting variables such as how many days per week or month people use/buy different drugs and it would allow us to sort the data by race and gender. It is a large data set like the NDSUH one. This data set also includes information on education, income, location, and employment. It would allow us to ask similarly interesting questions.\nWe are very interested in the NDSUH codebook data set, and while it is good that the NDSUH codebook data set is so diverse, this means it is also very large. The size of it has made it hard to work with and load into our repository and this will also make it harder to clean and organize. With the UMich data set, we may struggle to use it because it is not readily available as a CSV file and we would have to convert it into a format we could work with. Because there is so much data in the NDSUH data set, with so many different ways to interpret it and questions to ask, we could potentially struggle to come up with a good question(s) that are easily addressed by the data and not get lost in all of the data we have to work with. We could accidentally choose a question that is too specific and does not capitalize on the breadth of the data set, or we could go too broad and end up with a report that is too complex and does not achieve a meaningful or understandable interpretation of the data. We will also have to work hard to choose what to filter out and how to do that because it is impossible to use the entire data set and we will have to be careful in choosing which parts of it to work with and focus on. It could also be a good idea, with any data set that we choose, to weigh drug use against different factors such as education/income/location when possible so that we can see how much race actually influences drug use so we do not accidentally try to interpret false trends."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project: Exploring Drug Use and Contributing Factors",
    "section": "",
    "text": "Blog Post 7\n\n\n\n\n\n\n\nEnding\n\n\n\n\nWrapping the Project All Together (Part 2)\n\n\n\n\n\n\nDec 11, 2023\n\n\nInformation Illumin8ors\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 6\n\n\n\n\n\n\n\nEnding\n\n\n\n\nWrapping the Project All Together (Part 1)\n\n\n\n\n\n\nDec 4, 2023\n\n\nInformation Illumin8ors\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 5\n\n\n\n\n\n\n\nData Combination\n\n\n\n\nExploring other datasets as compliments to the original dataset.\n\n\n\n\n\n\nNov 20, 2023\n\n\nInformation Illumin8ors\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 4\n\n\n\n\n\n\n\nEDA\n\n\n\n\nTalking about EDA and some notable relationships\n\n\n\n\n\n\nNov 13, 2023\n\n\nInformation Illumin8ors\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 3\n\n\n\n\n\n\n\nData Cleaning\n\n\n\n\nGoing into the data cleaning process for the dataset used\n\n\n\n\n\n\nNov 6, 2023\n\n\nInformation Illumin8ors\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 2\n\n\n\n\n\n\n\nDataset Ethics and Equity\n\n\n\n\nData for Equity Understanding for our Data Set\n\n\n\n\n\n\nOct 30, 2023\n\n\nInformation Illumin8ors\n\n\n\n\n\n\n  \n\n\n\n\nBlog Post 1 - Datasets Search\n\n\n\n\n\n\n\nDataset Start\n\n\n\n\nDatasets Reasearch for beginning the Final Project\n\n\n\n\n\n\nOct 23, 2023\n\n\nInformation Illumin8ors\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Arianit is a undergraduate student at BU. Link to github https://github.com/ArianitBalidemaj\n\n\n\nEleanor is a senior in the math department at BU. Link to github: https://github.com/eleanorpaul05\n\n\n\nWenting is a statistics students at BU. Link to github: https://github.com/coriandercwt\n\n\n\n\n\n\n\n\n\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "about.html#arianit-balidemaj",
    "href": "about.html#arianit-balidemaj",
    "title": "About",
    "section": "",
    "text": "Arianit is a undergraduate student at BU. Link to github https://github.com/ArianitBalidemaj"
  },
  {
    "objectID": "about.html#eleanor-paul",
    "href": "about.html#eleanor-paul",
    "title": "About",
    "section": "",
    "text": "Eleanor is a senior in the math department at BU. Link to github: https://github.com/eleanorpaul05"
  },
  {
    "objectID": "about.html#wenting-chen",
    "href": "about.html#wenting-chen",
    "title": "About",
    "section": "",
    "text": "Wenting is a statistics students at BU. Link to github: https://github.com/coriandercwt"
  },
  {
    "objectID": "about.html#xiaojing-yang",
    "href": "about.html#xiaojing-yang",
    "title": "About",
    "section": "",
    "text": "This is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "Our motivation for engaging in Data Analysis of the NSDUH survey comes from our shared interest in finding out how drug use affects all areas of life in society. Understanding more about drug use is important because so much is unknown about drug use and being able to uncover certain relationships may be key in understanding and addressing drug use. For us we are super excited to explore such a huge dataset such as the NSDUH because we can take our time to explore the small key relationships between so many different variables throughout the dataset. Navigating through such a dataset took us a long time to find variables that we needed for analysis but it was perfect in the end because we were able to effectively show key relationships that help the general public understand more about drugs and their use.\nUltimately our goal is to provide key insights into how certain factors play a role in a person’s drug use even if they did a drug for one time. We were initially interested in finding out just about how race and drug use is affecting one another but we then soon realized that we also need to explore the factors for drug use and not just the relationship between the two. We then realized that a more holistic view of each factor into drug use would be more appropriate. These factors of income, age and location can play a role in how drug use and race correlate and associate together.\n\n\n\nThe variables we were highly interested in exploring is the relationship between drugs used and the race of the respondent in this survey. Being able to see the variables that factor into the relationship is important to understand how a person might be influenced to try and do drugs. The most important variables and factors help determine not only such a relationship of race and drug use but also the disparities between racial groups and drug use.\nGoing even further, we want to see what factors attribute to drug use in any way, that being income or location. These are important relationships to explore because it could provide insight into why or how someone could be introduced to drug use and what factors play a role. Some specific questions from the survey that play into our analysis are questions asking if a person has ever done such a drug and such a drug could be one of the 6 we are exploring which are cigarettes, marijuana, alcohol, cocaine, crack, heroine. Many factors could influence drug use such that two factors are reliant on each other. For example there could be relationships such that a young person with low income may or may not be more inclined to use drugs. These claims can only be made after such analysis of this dataset and its important to explore them.\nAlso at what age each person has done any of the respective substances and whether they continue to do those drugs or not. Income, age and location are also important factors when it comes to finding the factors as these can be associated with higher drug use or lower as well. We want to explore relationships like if you are younger will you be trying more drugs or will you try more drugs when you are older and how does the racial group aspect play a role. Age can also play along with income and location and it’s important to explore whether these factors intertwine with each other or are they stand alone. We aim to answer these questions and relationships below in the analysis.\n\n\n\nThe key question we are trying to answer is firstly how does race affect the drug use of a person. Going further, how does location, age, and income factor into this relationship."
  },
  {
    "objectID": "analysis.html#motivation-for-data-analysis-da",
    "href": "analysis.html#motivation-for-data-analysis-da",
    "title": "Analysis",
    "section": "",
    "text": "Our motivation for engaging in Data Analysis of the NSDUH survey comes from our shared interest in finding out how drug use affects all areas of life in society. Understanding more about drug use is important because so much is unknown about drug use and being able to uncover certain relationships may be key in understanding and addressing drug use. For us we are super excited to explore such a huge dataset such as the NSDUH because we can take our time to explore the small key relationships between so many different variables throughout the dataset. Navigating through such a dataset took us a long time to find variables that we needed for analysis but it was perfect in the end because we were able to effectively show key relationships that help the general public understand more about drugs and their use.\nUltimately our goal is to provide key insights into how certain factors play a role in a person’s drug use even if they did a drug for one time. We were initially interested in finding out just about how race and drug use is affecting one another but we then soon realized that we also need to explore the factors for drug use and not just the relationship between the two. We then realized that a more holistic view of each factor into drug use would be more appropriate. These factors of income, age and location can play a role in how drug use and race correlate and associate together."
  },
  {
    "objectID": "analysis.html#interested-variables",
    "href": "analysis.html#interested-variables",
    "title": "Analysis",
    "section": "",
    "text": "The variables we were highly interested in exploring is the relationship between drugs used and the race of the respondent in this survey. Being able to see the variables that factor into the relationship is important to understand how a person might be influenced to try and do drugs. The most important variables and factors help determine not only such a relationship of race and drug use but also the disparities between racial groups and drug use.\nGoing even further, we want to see what factors attribute to drug use in any way, that being income or location. These are important relationships to explore because it could provide insight into why or how someone could be introduced to drug use and what factors play a role. Some specific questions from the survey that play into our analysis are questions asking if a person has ever done such a drug and such a drug could be one of the 6 we are exploring which are cigarettes, marijuana, alcohol, cocaine, crack, heroine. Many factors could influence drug use such that two factors are reliant on each other. For example there could be relationships such that a young person with low income may or may not be more inclined to use drugs. These claims can only be made after such analysis of this dataset and its important to explore them.\nAlso at what age each person has done any of the respective substances and whether they continue to do those drugs or not. Income, age and location are also important factors when it comes to finding the factors as these can be associated with higher drug use or lower as well. We want to explore relationships like if you are younger will you be trying more drugs or will you try more drugs when you are older and how does the racial group aspect play a role. Age can also play along with income and location and it’s important to explore whether these factors intertwine with each other or are they stand alone. We aim to answer these questions and relationships below in the analysis."
  },
  {
    "objectID": "analysis.html#questions-for-analysis",
    "href": "analysis.html#questions-for-analysis",
    "title": "Analysis",
    "section": "",
    "text": "The key question we are trying to answer is firstly how does race affect the drug use of a person. Going further, how does location, age, and income factor into this relationship."
  },
  {
    "objectID": "analysis.html#necessary-libraries-and-datasets",
    "href": "analysis.html#necessary-libraries-and-datasets",
    "title": "Analysis",
    "section": "Necessary Libraries and Datasets",
    "text": "Necessary Libraries and Datasets\nBelow we start by first introducing the cleaned dataset and also the libraries that are needed to create plots and tables in a nice and aesthetically pleasing fashion.\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(usmap)\ncleaned_data &lt;- readRDS(here::here(\"dataset/cleaned_data_new.rds\"))"
  },
  {
    "objectID": "analysis.html#initial-findings-and-relationships---eda",
    "href": "analysis.html#initial-findings-and-relationships---eda",
    "title": "Analysis",
    "section": "Initial Findings and Relationships - EDA",
    "text": "Initial Findings and Relationships - EDA\n\nlibrary(ggthemes)\ncleaned_data |&gt;\n  filter(cocage &lt; 120) |&gt;\n  ggplot(aes(x = cocage)) + geom_bar(show.legend = TRUE) + facet_wrap(vars(NEWRACE2)) +\n  labs(title = \"Age When First Used Cocaine by Race\", x = \"Age\", y = \"Frequency\")\n\n\n\ncleaned_data |&gt;\n  filter(if_all(c(AL30EST, MR30EST), \\(v) v &lt; 85)) |&gt;\n  arrange(desc(AL30EST)) |&gt;\n  arrange(desc(MR30EST)) |&gt;\n  select(AL30EST, MR30EST) |&gt;\n  count()\n\n  n\n1 5\n\n# distinct on 2 columns only shows combinations\n\ncleaned_data |&gt;\n  filter(AL30EST &lt; 85) |&gt;\n  select(AL30EST) |&gt;\n  arrange(desc(AL30EST)) |&gt;\n  distinct() \n\n      AL30EST\n22304       6\n4488        5\n1559        4\n460         3\n3099        2\n2247        1\n\ncleaned_data |&gt;\n  filter(MR30EST &lt; 85) |&gt;\n  select(MR30EST) |&gt;\n  arrange(desc(MR30EST)) |&gt;\n  distinct() \n\n      MR30EST\n1238        6\n27004       5\n3495        4\n460         2\n9876        1\n\ncleaned_data |&gt;\n  select(NEWRACE2) |&gt;\n  count(NEWRACE2) \n\n                 NEWRACE2     n\n1                   Asian  3234\n2            Black/Afr Am  6743\n3                Hispanic  9929\n4      More than one race  2524\n5     Native Am/AK Native   587\n6 Native HI/Other Pac Isl   226\n7                   White 34791\n\ncleaned_data |&gt;\n  filter(AL30EST &lt; 85) |&gt;\n  group_by(NEWRACE2, AL30EST) |&gt;\n  summarize(AL30EST = mean(AL30EST)) |&gt;\n  ggplot(aes(x = AL30EST, y = NEWRACE2)) + \n  geom_line() + \n  theme_minimal()\n\n`summarise()` has grouped output by 'NEWRACE2'. You can override using the\n`.groups` argument.\n\n\n\n\ncleaned_data |&gt;\n  filter(AL30EST &lt; 85) |&gt;\n  group_by(NEWRACE2, AL30EST) |&gt;\n  summarize(AL30EST = mean(AL30EST)) |&gt;\n  ggplot(aes(x = AL30EST)) + \n  geom_bar(aes(fill = NEWRACE2)) + \n  scale_fill_colorblind() + \n  theme_minimal()\n\n`summarise()` has grouped output by 'NEWRACE2'. You can override using the\n`.groups` argument.\n\n\n\n\n#cleaned_data |&gt;\n # filter(AL30EST &lt; 85) |&gt;\n # filter(MR30EST &lt; 85) |&gt;\n#  filter(HR30EST &lt; 85) |&gt;\n # select(AL30EST, MR30EST, HR30EST)\n#  arrange(desc(AL30EST)) |&gt;\n#  arrange(desc(MR30EST)) |&gt;\n#  arrange(desc(CC30EST)) |&gt;\n#  arrange(desc(CR30EST)) |&gt;\n# arrange(desc(HR30EST)) |&gt;\n# filter(AL30EST == first(AL30EST)) |&gt;\n# filter(MR30EST == first(MR30EST)) |&gt;\n# filter(CC30EST == first(CC30EST)) |&gt;\n# filter(CR30EST == first(CR30EST)) |&gt;\n# filter(HR30EST == first(HR30EST)) |&gt;\n# select(AL30EST, MR30EST, CC30EST, CR30EST, HR30EST)"
  },
  {
    "objectID": "analysis.html#alcohol-use-plots",
    "href": "analysis.html#alcohol-use-plots",
    "title": "Analysis",
    "section": "Alcohol Use Plots",
    "text": "Alcohol Use Plots\n\n# option 1 for estimated number of days alcohol used in past 30 days by race\ncleaned_data |&gt;\n  filter(AL30EST &lt; 85) |&gt;\n  group_by(NEWRACE2, AL30EST) |&gt;\n  summarize(AL30EST = mean(AL30EST)) |&gt;\n  ggplot(aes(x = AL30EST, y = NEWRACE2)) + \n  geom_line() + \n  theme_minimal() +\n  labs(title = \"Estimated Number of Days Alcohol Used in Past 30 Days by Race\", x = \"Estimated number of days\", y = \"Race Category\")\n\n`summarise()` has grouped output by 'NEWRACE2'. You can override using the\n`.groups` argument.\n\n\n\n\n# option 2 for estimated number of days alcohol used in past 30 days by race\ncleaned_data |&gt;\n  filter(AL30EST &lt; 85) |&gt;\n  group_by(NEWRACE2, AL30EST) |&gt;\n  summarize(AL30EST = mean(AL30EST)) |&gt;\n  ggplot(aes(x = AL30EST)) + \n  geom_bar(aes(fill = NEWRACE2)) + \n  scale_fill_colorblind() + \n  theme_minimal() +\n  labs(title = \"Estimated Number of Days Alcohol Used in Past 30 Days by Race\", x = \"AL30EST\", y = \"\")\n\n`summarise()` has grouped output by 'NEWRACE2'. You can override using the\n`.groups` argument.\n\n\n\n\n# updated the cocaine age plot to make it easier to read\ncleaned_data |&gt;\n  filter(cocage &lt; 120) |&gt;\n  ggplot(aes(x = cocage)) + geom_bar(show.legend = TRUE) + facet_wrap(vars(NEWRACE2), scales = \"free\") +\n  labs(title = \"Age When First Used Cocaine by Race\", x = \"Age\", y = \"Frequency\")\n\n\n\ncleaned_data |&gt;\n  ggplot() +\n  geom_line(aes(x = NEWRACE2, y = AL30EST, color = \"red\")) + geom_line(aes(x = NEWRACE2, y = AL30EST, color = \"blue\"))\n\n\n\n\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this"
  },
  {
    "objectID": "analysis.html#plot-for-alcohol-use-last-12-months-by-race",
    "href": "analysis.html#plot-for-alcohol-use-last-12-months-by-race",
    "title": "Analysis",
    "section": "Plot for Alcohol Use last 12 months by Race",
    "text": "Plot for Alcohol Use last 12 months by Race\n\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\n\nfile_path &lt;- \"dataset/cleaned_data_new.rds\"\n\ncleaned_data &lt;- readRDS(file_path)\n\n# Filter out records where alcyrtot is greater than 365\nfiltered_data &lt;- cleaned_data %&gt;% \n  filter(alcyrtot &lt;= 365)\n\nboxplot_alcohol_use &lt;- ggplot(filtered_data, aes(x = factor(NEWRACE2), y = alcyrtot, fill = factor(NEWRACE2))) +\n  geom_boxplot() +\n  labs(title = \"TOTAL # OF DAYS USED ALCOHOL IN PAST 12 MOS by RACE (Excluding &gt;365 days)\",\n       x = \"Race\",\n       y = \"Total Days of Alcohol Use\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\nprint(boxplot_alcohol_use)"
  },
  {
    "objectID": "analysis.html#plot-for-marijuna-use-at-certain-age-with-race",
    "href": "analysis.html#plot-for-marijuna-use-at-certain-age-with-race",
    "title": "Analysis",
    "section": "Plot for Marijuna Use at certain Age with Race",
    "text": "Plot for Marijuna Use at certain Age with Race\n\nmarj_data &lt;- cleaned_data |&gt;\n  select(NEWRACE2, mjage, mjrec, mrdaypwk, MJDAY30A, MR30EST) |&gt;\n  filter(mjage &lt; 83)\n\n# First tried marijuana plot\nmarj_age_plot &lt;- ggplot(marj_data, aes(x = factor(NEWRACE2), y = mjage, color = factor(NEWRACE2), fill=factor(NEWRACE2))) +\n  geom_boxplot() +\n  labs(title = \"Age at which People First Tried Using Marijuana\",\n       x = \"Race\",\n       y = \"Age when First Tried\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\nmarj_age_plot"
  },
  {
    "objectID": "analysis.html#logisitic-regression-models",
    "href": "analysis.html#logisitic-regression-models",
    "title": "Analysis",
    "section": "Logisitic Regression Models",
    "text": "Logisitic Regression Models\nImportant to note that the baselines/intercepts are the Asian Population\n\nSubstance Use with Race\n\ndrug_use_with_race &lt;- cleaned_data |&gt;\n  select(NEWRACE2, cigever, cigage, mjever, mjage, alcever, cocever, cocage, crkever, crkage, herever, herage, income, COUTYP4) |&gt;\n  mutate(drug_use = ifelse(cigever==1 | mjever==1 | alcever==1 | cocever==1 | crkever==1 | herever==1, 1, 0))\n\n# Model for the Substance Use vs Race \nmodel_sub &lt;- glm(drug_use ~ NEWRACE2, data = drug_use_with_race, family = \"binomial\")\n\ntidy_output &lt;- tidy(model_sub)|&gt;\n  mutate(term = ifelse(term == \"(Intercept)\", \"Asian\", str_replace(term, \"NEWRACE2\", \"\")))\n\nconf_intervals &lt;- confint(model_sub)\n\nWaiting for profiling to be done...\n\nodds_ratios &lt;- exp(coef(model_sub))\n\nodds_ratios_df &lt;- data.frame(\n  Odds_Ratio = odds_ratios\n)\n\noutput_table &lt;- cbind(tidy_output, conf_intervals,odds_ratios_df) |&gt;\n  rename(Race = term) |&gt;\n  select(-statistic,-std.error) |&gt;\n  rownames_to_column(var = \"RowNames\") |&gt;\n  select(-RowNames)\n\noutput_table\n\n                     Race  estimate       p.value      2.5 %    97.5 %\n1                   Asian 0.4230185  5.980073e-32 0.35270632 0.4936763\n2            Black/Afr Am 0.2169798  8.887671e-07 0.13037484 0.3034431\n3                Hispanic 0.3064576  2.447070e-13 0.22431618 0.3883978\n4      More than one race 0.5386455  4.742597e-21 0.42677403 0.6510673\n5     Native Am/AK Native 0.9149979  2.235867e-17 0.70679838 1.1300603\n6 Native HI/Other Pac Isl 0.2967970  4.240218e-02 0.01391972 0.5880282\n7                   White 0.9660087 8.507647e-140 0.89063740 1.0410935\n  Odds_Ratio\n1   1.526562\n2   1.242319\n3   1.358604\n4   1.713684\n5   2.496770\n6   1.345542\n7   2.627437\n\n\n\n\nSubstance Use with Race and Income as a Factor of Each Other\nWe are gonna assume for the model here that the hypothesis is that there is no association between likelihood of trying drugs ever and race group as well as Income.\n\ndrug_use_with_race &lt;- cleaned_data |&gt;\n  select(NEWRACE2, cigever, cigage, mjever, mjage, alcever, cocever, cocage, crkever, crkage, herever, herage, income, COUTYP4) |&gt;\n  mutate(drug_use = ifelse(cigever==1 | mjever==1 | alcever==1 | cocever==1 | crkever==1 | herever==1, 1, 0))\n\n# Model for the Substance Use vs Race and Income being Independent\nmodel_sub &lt;- glm(drug_use ~ NEWRACE2 + factor(income), data = drug_use_with_race, family = \"binomial\")\n\ntidy_output &lt;- tidy(model_sub)|&gt;\n  mutate(term = ifelse(term == \"(Intercept)\", \"Asian\", str_replace(term, \"NEWRACE2\", \"\")))\n\nconf_intervals &lt;- confint(model_sub)\n\nWaiting for profiling to be done...\n\nodds_ratios &lt;- exp(coef(model_sub))\n\nodds_ratios_df &lt;- data.frame(\n  Odds_Ratio = odds_ratios\n)\n\noutput_table &lt;- cbind(tidy_output, conf_intervals,odds_ratios_df) |&gt;\n  rename(Race = term) |&gt;\n  select(-statistic,-std.error) |&gt;\n  rownames_to_column(var = \"RowNames\") |&gt;\n  select(-RowNames)\n\noutput_table\n\n                      Race    estimate       p.value        2.5 %      97.5 %\n1                    Asian  0.43220576  2.367549e-24  0.349172293 0.515564083\n2             Black/Afr Am  0.18985960  2.310819e-05  0.101865474 0.277712630\n3                 Hispanic  0.27749672  5.606697e-11  0.194404409 0.360388189\n4       More than one race  0.52304960  7.531640e-20  0.410900087 0.635744654\n5      Native Am/AK Native  0.89006077  1.949330e-16  0.681210224 1.105732430\n6  Native HI/Other Pac Isl  0.27765871  5.783353e-02 -0.005486904 0.569140447\n7                    White  0.95602397 1.418343e-136  0.880544055 1.031217033\n8          factor(income)2  0.06230228  3.513414e-02  0.004294946 0.120217926\n9          factor(income)3  0.06663508  5.392007e-02 -0.001080723 0.134440939\n10         factor(income)4 -0.04903027  8.246861e-02 -0.104456665 0.006223479\n   Odds_Ratio\n1   1.5406521\n2   1.2090798\n3   1.3198218\n4   1.6871650\n5   2.4352776\n6   1.3200356\n7   2.6013329\n8   1.0642840\n9   1.0689053\n10  0.9521523\n\n\n\n\nSubstance Use with Race and Income as a Factor of Each Other\nSame as before, we are gonna assume for the model here that the hypothesis is that there is no association between likelihood of trying drugs ever and race group as well as Income.\n\n# Model for the Substance Use vs Race and Income\nmodel_sub_income &lt;- glm(drug_use ~ NEWRACE2*factor(income), data = drug_use_with_race, family = \"binomial\")\n\ntidy_output_income &lt;- tidy(model_sub_income)|&gt;\n  mutate(term = ifelse(term == \"(Intercept)\", \"Asian\", str_replace(term, \"NEWRACE2\", \"\")))\n\nconf_intervals_income &lt;- confint(model_sub_income)\n\nWaiting for profiling to be done...\n\nodds_ratios_income &lt;- exp(coef(model_sub_income))\n\noutput_table &lt;- cbind(tidy_output_income,conf_intervals_income, odds_ratios_income) |&gt;\n  select(-statistic,-std.error) |&gt;\n  rownames_to_column(var = \"RowNames\") |&gt;\n  select(-RowNames)\n\noutput_table\n\n                                      term    estimate      p.value       2.5 %\n1                                    Asian  0.37292635 1.345596e-04  0.18246349\n2                             Black/Afr Am  0.11186896 2.949858e-01 -0.09851296\n3                                 Hispanic  0.23248191 3.089959e-02  0.02039498\n4                       More than one race  0.86302950 1.378528e-09  0.58512391\n5                      Native Am/AK Native  1.18663973 7.783582e-09  0.79323211\n6                  Native HI/Other Pac Isl  0.19346912 5.049058e-01 -0.36635675\n7                                    White  1.15666263 5.192674e-28  0.94904963\n8                          factor(income)2 -0.12203449 3.391732e-01 -0.37281039\n9                          factor(income)3 -0.10957638 4.482291e-01 -0.39289818\n10                         factor(income)4  0.15183678 1.633865e-01 -0.06262576\n11            Black/Afr Am:factor(income)2  0.25384628 7.407449e-02 -0.02440743\n12                Hispanic:factor(income)2  0.13387908 3.383557e-01 -0.13992600\n13      More than one race:factor(income)2  0.13512413 4.727231e-01 -0.23406687\n14     Native Am/AK Native:factor(income)2 -0.14064382 6.244183e-01 -0.70507021\n15 Native HI/Other Pac Isl:factor(income)2  0.29323796 4.608850e-01 -0.48827059\n16                   White:factor(income)2  0.18257528 1.822914e-01 -0.08546121\n17            Black/Afr Am:factor(income)3  0.44067407 8.601613e-03  0.11210005\n18                Hispanic:factor(income)3  0.26560468 9.973084e-02 -0.05067364\n19      More than one race:factor(income)3 -0.20161411 3.497527e-01 -0.62392684\n20     Native Am/AK Native:factor(income)3 -0.04599576 9.030409e-01 -0.77094091\n21 Native HI/Other Pac Isl:factor(income)3  0.35411112 5.003475e-01 -0.65789666\n22                   White:factor(income)3  0.04318896 7.787989e-01 -0.25830533\n23            Black/Afr Am:factor(income)4  0.19147894 1.423409e-01 -0.06368124\n24                Hispanic:factor(income)4  0.22970150 6.810967e-02 -0.01651802\n25      More than one race:factor(income)4 -0.72698083 1.050365e-05 -1.05142606\n26     Native Am/AK Native:factor(income)4 -0.67531093 2.101417e-02 -1.24918091\n27 Native HI/Other Pac Isl:factor(income)4  0.07809916 8.399788e-01 -0.68247052\n28                   White:factor(income)4 -0.43754970 1.938581e-04 -0.66710176\n        97.5 % odds_ratios_income\n1   0.56564679          1.4519774\n2   0.32045564          1.1183663\n3   0.44284905          1.2617276\n4   1.14389622          2.3703307\n5   1.60082466          3.2760543\n6   0.77668294          1.2134519\n7   1.36251967          3.1793050\n8   0.12786845          0.8851178\n9   0.17374929          0.8962137\n10  0.36463323          1.1639702\n11  0.53282959          1.2889736\n12  0.40835795          1.1432546\n13  0.50381314          1.1446789\n14  0.42305829          0.8687987\n15  1.07524996          1.3407618\n16  0.45129630          1.2003045\n17  0.76971771          1.5537542\n18  0.58198987          1.3042194\n19  0.22157742          0.8174103\n20  0.71645675          0.9550460\n21  1.41902297          1.4249135\n22  0.34464194          1.0441352\n23  0.44805755          1.2110393\n24  0.47720430          1.2582244\n25 -0.40449272          0.4833662\n26 -0.09960831          0.5089981\n27  0.83845622          1.0812299\n28 -0.20670462          0.6456164\n\n\n\n\nSubstance Use with Race and Location\n\n# Model for the Substance Use vs Race and Location Independent\nmodel_sub_loc &lt;- glm(drug_use ~ NEWRACE2+factor(COUTYP4), data = drug_use_with_race, family = \"binomial\")\n\ntidy_output_loc &lt;- tidy(model_sub_loc)|&gt;\n  mutate(term = ifelse(term == \"(Intercept)\", \"Asian\", str_replace(term, \"NEWRACE2\", \"\")))\n\nconf_intervals_loc &lt;- confint(model_sub_loc)\n\nWaiting for profiling to be done...\n\nodds_ratios_loc &lt;- exp(coef(model_sub_loc))\n\noutput_table &lt;- cbind(tidy_output_loc,conf_intervals_loc, odds_ratios_loc) |&gt;\n  select(-statistic,-std.error) |&gt;\n  rownames_to_column(var = \"RowNames\") |&gt;\n  select(-RowNames)\n\noutput_table\n\n                     term    estimate       p.value       2.5 %      97.5 %\n1                   Asian  0.45062602  6.304180e-35  0.37915407  0.52243937\n2            Black/Afr Am  0.23393351  1.284662e-07  0.14703895  0.32069011\n3                Hispanic  0.31732536  3.765679e-14  0.23504868  0.39940310\n4      More than one race  0.56638740  6.968352e-23  0.45393187  0.67939271\n5     Native Am/AK Native  0.97496895  3.096033e-19  0.76503806  1.19166536\n6 Native HI/Other Pac Isl  0.33353408  2.277358e-02  0.05020109  0.62520075\n7                   White  0.99852745 9.207438e-145  0.92199753  1.07478905\n8        factor(COUTYP4)2 -0.08207244  1.529114e-04 -0.12455399 -0.03958344\n9        factor(COUTYP4)3 -0.12164089  1.532389e-05 -0.17669046 -0.06641247\n  odds_ratios_loc\n1       1.5692943\n2       1.2635605\n3       1.3734494\n4       1.7618905\n5       2.6510849\n6       1.3958926\n7       2.7142820\n8       0.9212052\n9       0.8854663\n\n\n\n\nSubstance Use with Race and Location as a Factor of Each Other\n\n# Model for the Substance Use vs Race and Location\nmodel_sub_loc &lt;- glm(drug_use ~ NEWRACE2*factor(COUTYP4), data = drug_use_with_race, family = \"binomial\")\n\ntidy_output_loc &lt;- tidy(model_sub_loc)|&gt;\n  mutate(term = ifelse(term == \"(Intercept)\", \"Asian\", str_replace(term, \"NEWRACE2\", \"\")))\n\nconf_intervals_loc &lt;- confint(model_sub_loc)\n\nWaiting for profiling to be done...\n\nodds_ratios_loc &lt;- exp(coef(model_sub_loc))\n\noutput_table &lt;- cbind(tidy_output_loc,conf_intervals_loc, odds_ratios_loc) |&gt;\n  select(-statistic,-std.error) |&gt;\n  rownames_to_column(var = \"RowNames\") |&gt;\n  select(-RowNames)\n\noutput_table\n\n                                       term    estimate       p.value\n1                                     Asian  0.36543732  2.550892e-17\n2                              Black/Afr Am  0.34041651  1.216648e-09\n3                                  Hispanic  0.35244104  7.419889e-12\n4                        More than one race  0.49414738  7.066146e-10\n5                       Native Am/AK Native  0.56409864  1.030904e-02\n6                   Native HI/Other Pac Isl  0.28688786  2.518990e-01\n7                                     White  1.15261850 1.692499e-123\n8                          factor(COUTYP4)2  0.18568679  2.406502e-02\n9                          factor(COUTYP4)3  0.18844779  3.021688e-01\n10            Black/Afr Am:factor(COUTYP4)2 -0.26268043  8.539462e-03\n11                Hispanic:factor(COUTYP4)2 -0.14979336  1.144613e-01\n12      More than one race:factor(COUTYP4)2 -0.03597057  7.778876e-01\n13     Native Am/AK Native:factor(COUTYP4)2  0.35986711  2.260673e-01\n14 Native HI/Other Pac Isl:factor(COUTYP4)2 -0.27090552  4.115780e-01\n15                   White:factor(COUTYP4)2 -0.38603671  1.102135e-05\n16            Black/Afr Am:factor(COUTYP4)3 -0.47413037  1.667979e-02\n17                Hispanic:factor(COUTYP4)3 -0.18671829  3.433741e-01\n18      More than one race:factor(COUTYP4)3  0.05667737  8.001668e-01\n19     Native Am/AK Native:factor(COUTYP4)3  0.30279679  3.422049e-01\n20 Native HI/Other Pac Isl:factor(COUTYP4)3  0.37224966  4.189567e-01\n21                   White:factor(COUTYP4)3 -0.39647123  3.325521e-02\n         2.5 %      97.5 % odds_ratios_loc\n1   0.28103294  0.45027367       1.4411441\n2   0.23061867  0.45018243       1.4055329\n3   0.25147900  0.45320159       1.4225358\n4   0.33778053  0.65207321       1.6391001\n5   0.14398410  1.00918479       1.7578626\n6  -0.19423636  0.79199300       1.3322748\n7   1.05690195  1.24808807       3.1664735\n8   0.02488828  0.34759467       1.2040451\n9  -0.16520382  0.55241117       1.2073740\n10 -0.45880538 -0.06723384       0.7689876\n11 -0.33619741  0.03585345       0.8608859\n12 -0.28606451  0.21388812       0.9646687\n13 -0.22556226  0.94276131       1.4331389\n14 -0.92335184  0.37314925       0.7626886\n15 -0.55867326 -0.21438584       0.6797456\n16 -0.86735716 -0.08955710       0.6224261\n17 -0.57795498  0.19589207       0.8296774\n18 -0.38530990  0.49348803       1.0583143\n19 -0.32879305  0.92276375       1.3536394\n20 -0.51635806  1.29866490       1.4509952\n21 -0.76721944 -0.03563780       0.6726896"
  },
  {
    "objectID": "analysis.html#testing-the-plot-of-location-with-substance-use",
    "href": "analysis.html#testing-the-plot-of-location-with-substance-use",
    "title": "Analysis",
    "section": "Testing the plot of location with substance use",
    "text": "Testing the plot of location with substance use\n\nmetro_test &lt;- cleaned_data |&gt;\n  filter(CIG30AV &lt; 94) |&gt;\n  ggplot(aes(x = CIG30AVG)) + geom_bar(aes(fill = NEWRACE2)) + facet_wrap(vars(COUTYP4))"
  },
  {
    "objectID": "analysis.html#note-on-attribution",
    "href": "analysis.html#note-on-attribution",
    "title": "Analysis",
    "section": "Note on Attribution",
    "text": "Note on Attribution\nIn general, you should try to provide links to relevant resources, especially those that helped you. You don’t have to link to every StackOverflow post you used but if there are explainers on aspects of the data or specific models that you found helpful, try to link to those. Also, try to link to other sources that might support (or refute) your analysis. These can just be regular hyperlinks. You don’t need a formal citation.\nIf you are directly quoting from a source, please make that clear. You can show quotes using &gt; like this"
  },
  {
    "objectID": "analysis.html#limitations-of-analysis",
    "href": "analysis.html#limitations-of-analysis",
    "title": "Analysis",
    "section": "Limitations of Analysis",
    "text": "Limitations of Analysis\nIn our analysis of the data, there were a few limitations that we had to keep in mind. The first is that both when conducting and reading the analysis, remember that the results on substance use are based on respondent’s memories so that introduces error because people may have falsely reported their true substance use. Another source of error that we had to address was that the results of our plots were pretty skewed because the number of white respondents was much higher than the number of respondents of other race categories. This was falsely making it look like substance use was much higher for the white race category than it was for others. To address this, we tried using proportions instead."
  },
  {
    "objectID": "analysis.html#rubric-on-this-page",
    "href": "analysis.html#rubric-on-this-page",
    "title": "Analysis",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nIntroduce what motivates your Data Analysis (DA)\n\nWhich variables and relationships are you most interested in?\nWhat questions are you interested in answering?\nProvide context for the rest of the page. This will include figures/tables that illustrate aspects of the data of your question.\n\nModeling and Inference\n\nThe page will include some kind of formal statistical model. This could be a linear regression, logistic regression, or another modeling framework.\nExplain the techniques you used for validating your results.\nDescribe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.\n\nExplain the flaws and limitations of your analysis\n\nAre there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions?\n\nClarity Figures\n\nAre your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?\nEach figure should provide a key insight. Too many figures or other data summaries can detract from this. (While not a hard limit, around 5 total figures is probably a good target.)\nDefault lm output and plots are typically not acceptable.\n\nClarity of Explanations\n\nHow well do you explain each figure/result?\nDo you provide interpretations that suggest further analysis or explanations for observed phenomenon?\n\nOrganization and cleanliness.\n\nMake sure to remove excessive warnings, use clean easy-to-read code, organize with sections or multiple pages, use bullets, etc.\nThis page should be self-contained."
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "Big Picture",
    "section": "",
    "text": "This comes from the file big_picture.Rmd.\nThink of this page as your 538/Upshot style article. This means that you should try to tell a story through the data and your analysis. Read articles from those sites and similar sites to get a feeling for what they are like. Importantly, these should be geared towards the general public. You shouldn’t assume the reader understands how to interpret a linear regression. Focus on interpretation and visualizations."
  },
  {
    "objectID": "big_picture.html#rubric-on-this-page",
    "href": "big_picture.html#rubric-on-this-page",
    "title": "Big Picture",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nTitle\n\nYour big picture page should have a creative/click-bait-y title/headline that provides a hint about your thesis.\n\nClarity of Explanation\n\nYou should have a clear thesis/goal for this page. What are you trying to show? Make sure that you explain your analysis in detail but don’t go into top much mathematics or statistics. The audience for this page is the general public (to the extent possible). Your thesis should be a statement, not a question.\nEach figure should be very polished and also not too complicated. There should be a clear interpretation of the figure so the figure has a clear purpose. Even something like a histogram can be difficult to interpret for non-experts.\n\nCreativity\n\nDo your best to make things interesting. Think of a story. Think of how each part of your analysis supports the previous part or provides a different perspective.\n\nThis page should be self-contained.\n\nNote: This page should have no code visible, i.e. use #| echo: FALSE."
  },
  {
    "objectID": "big_picture.html#rubric-other-components",
    "href": "big_picture.html#rubric-other-components",
    "title": "Big Picture",
    "section": "Rubric: Other components",
    "text": "Rubric: Other components\n\nInteractive\nYou will also be required to make an interactive dashboard like this one.\nYour Big Data page should include a link to an interactive dashboard. The dashboard should be created either using Shiny or FlexDashboard (or another tool with professor’s approval). This interactive component should in some way support your thesis from your big picture page. Good interactives often provide both high-level understanding of the data while allowing a user to investigate specific scenarios, observations, subgroups, etc.\n\nQuality and ease of use of the interactive components. Is it clear what can be explored using your interactive components? Does it enhance and reinforce your conclusions from the Big Picture? Plotly with default hover text will get no credit. Be creative!\n\n\n\nVideo Recording\nMake a video recording (probably using Zoom) demonstrating your interactive components. You should provide a quick explanation of your data and demonstrate some of the conclusions from your EDA. This video should be no longer than 4 minutes. Include a link to your video (and password if needed) in your README.md file on your Github repository. You are not required to provide a link on the website. This can be presented by any subset of the team members.\n\n\nRest of the Site\nFinally, here are important things to keep in mind for the rest of the site.\nThe main title of your page is informative. Each post has an author/description/informative title. All lab required posts are present. Each page (including the home page) has a nice featured image associated with it. Your about page is up to date and clean. You have removed the generic posts from the initial site template."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "We found the data set by googling keywords such as “mental health, race, age, substance abuse” accompanied with “data set, csv, R”. This allowed us to find the codebook from the “Substance Abuse and Mental Health Services Administration”, describing a survey on substance abuse, mental health, and race from 2021. This survey was the “National Survey on Drug Use and Health”. We deemed this source reputable and we found an R file to download from: https://www.datafiles.samhsa.gov/dataset/national-survey-drug-use-and-health-2021-nsduh-2021-ds0001. The link to the codebook is here:\nhttps://www.datafiles.samhsa.gov/sites/default/files/field-uploads-protected/studies/NSDUH-2021/NSDUH-2021-datasets/NSDUH-2021-DS0001/NSDUH-2021-DS0001-info/NSDUH-2021-DS0001-info-codebook.pdf.\n The survey was conducted by SAMSHA - Substance Abuse and Mental Health Services Administration which is a government agency for the United States of America.\nAnother dataset we found that we needed was the Census data for 2020 and getting the counties with their respective population count. This was important to to plot the counties onto a map of America so to show which cities are clustered with people more and associate it with the survey of which areas are considered large, small, or non metro areas. There are many variables that are collected by the Bureau but the most important ones that are relevant to the main dataset is the county names to get each county and the population size of each county such that it can be plotted onto the map of the United States as a heatmap of population density. The link to the US Census data for 2020 is https://www.census.gov/programs-surveys/decennial-census/decade/2020/2020-census-results.html.\n\n\n\n\nThe primary purpose of this data and the NSDUH organization was to measure the frequency and relationship between substance abuse and mental health issues. The target population is the civilian and noninstitutionalized one. This survey was sent out to and filled out by individual persons in the USA, aged 12 and over, the data was collected cross-sectionally. The survey collectors warn that this data is dependent on respondent’s truthfulness and memory, and should thus be taken with a grain of salt. Also, this survey does not include data from citizens who are active-duty military members or living in institutional group shelters (homeless shelters, hospitals, prisons, etc.). They warn that this may underestimate the use of certain drugs like heroin.\nFor the creation of the census, it was created by the United States Census Bureau Agency. It is done every 10 years and is a way to produce data on the American people and the economy of the United States as well. The hope in doing this is that the United States gets a better sense of how the American people are doing and where many people are located and understanding more about what kinds of decisions need to be made for the people or society. The census is conducted through electronic questionnaires to business, homes and many other places where someone may be. Sometimes they will sample people and conduct in person interviews as well but it is not possible to do it for every single person in America so relying on electronic questionnaires and other forms of filling the census are essential in the Bereau’s methods of collection.\n\n\n\nWhile we used the R file available to download to make the cleaned data set in our final project repository, we used the codebook to actually understand the data set R dataset file. The codebook contained information about each column and it was broken down into sections of self-administered substance abuse, imputed substance abuse, other self-administered sections, demographics, and geographic. We divided the sections and went through them, when sorting through the substance abuse sections, we stayed consistent in the types of columns we chose, those were: “age when first used”, “time since last used”, “number of days per week used in last 12 months”, and “best estimate of how many times used in last 30 days”.\nWhile the data set we are using from the 2021 NSDUH contains bountiful information concerning substance use, race, income, mental health, education, and age, it does not include very specific location information. The main information provided about the location of the survey respondents is stored in the variables “PDEN10” and “COUNTYP4”. This\n\n\n\nThis is the link to the script, cleaning script. The Script cleans the data by keeping only the columns that have enough responses to the questions and also are highly relevant questions that can be used in understanding the data. Our strategy is too use the columns with the most value in analysis. Questions like “Have you ever smoked a cigarette” have high response rates and gives key insight into how we can associate drug/substance use with what we are trying to look into. The script filtering involved taking all the questions we deemed qualified to be included in and the rest of the 2,800 variables in this dataset to be filtered out and to keep a consistent set of questions for the analysis use. Such selecting looks like:\ndrug_health_data_clean_new &lt;- PUF2021_100622 |&gt;\n  select(QUESTID2, filedate,\n         cigever, cigage, mjever, mjage, alcever, cocever, cocage, crkever, crkage, herever, herage, UD5ILLANY, ... (other variables)\nThen we save the dataframe into a rds file for storage purposes and continue to the other datasets.\nThe cleaning for the census dataset goes\nTo clean the CBSA data set, the readxl package was used to read the CBSA excel file. The data was already pretty clean, but in the original file there was a blank row and a few header rows, so we had to make sure to skip those. Then the columns were labeled and any missing values were converted to read as NA. A similar procedure was followed to read in an excel file containing Census data. With the Census data, we were interested in county populations by state. One thing we had to consider with the Census data was that it contained a row at the start of each state where the county name and the state name were the same and this row listed the state’s total population. While we did not remove this row when cleaning the data set, we were aware of it and would filter it out if necessary. For example, it was not necessary to filter out this row when we created a merged CBSA/CENSUS dataset since we joined the datasets on the conditions that a pair of state and county names matched in both datasets and since the CBSA data did not have any such pairs, it would automatically be eliminated.\nOne important thing that we had to look into when cleaning the CBSA and CENSUS data sets was the column types. We tried using the character() function to tell us the types of columns we were dealing with to pass into the read_excel() function. However, we still ran into parsing errors because the excel files had numeric values stored as texts. To address this issue, we used a feature of read_excel() that allowed us to pass in a column type “guess”, allowing R to guess at/decide on how it wanted to read in the numeric values stored as text which fixed the error message and produced readable data. Once this error had been fixed, we were able to save the cleaned CBSA and Census data sets as RDS files. To support our location information data, we also read in an excel dataset containing rural urban continuum codes which was then saved as an RDS file. This data set was easy enough to clean and we employed the same techniques as those mentioned for the Census and CBSA data sets."
  },
  {
    "objectID": "data.html#understanding-the-dataset",
    "href": "data.html#understanding-the-dataset",
    "title": "Data",
    "section": "",
    "text": "We found the data set by googling keywords such as “mental health, race, age, substance abuse” accompanied with “data set, csv, R”. This allowed us to find the codebook from the “Substance Abuse and Mental Health Services Administration”, describing a survey on substance abuse, mental health, and race from 2021. This survey was the “National Survey on Drug Use and Health”. We deemed this source reputable and we found an R file to download from: https://www.datafiles.samhsa.gov/dataset/national-survey-drug-use-and-health-2021-nsduh-2021-ds0001. The link to the codebook is here:\nhttps://www.datafiles.samhsa.gov/sites/default/files/field-uploads-protected/studies/NSDUH-2021/NSDUH-2021-datasets/NSDUH-2021-DS0001/NSDUH-2021-DS0001-info/NSDUH-2021-DS0001-info-codebook.pdf.\n The survey was conducted by SAMSHA - Substance Abuse and Mental Health Services Administration which is a government agency for the United States of America.\nAnother dataset we found that we needed was the Census data for 2020 and getting the counties with their respective population count. This was important to to plot the counties onto a map of America so to show which cities are clustered with people more and associate it with the survey of which areas are considered large, small, or non metro areas. There are many variables that are collected by the Bureau but the most important ones that are relevant to the main dataset is the county names to get each county and the population size of each county such that it can be plotted onto the map of the United States as a heatmap of population density. The link to the US Census data for 2020 is https://www.census.gov/programs-surveys/decennial-census/decade/2020/2020-census-results.html.\n\n\n\n\nThe primary purpose of this data and the NSDUH organization was to measure the frequency and relationship between substance abuse and mental health issues. The target population is the civilian and noninstitutionalized one. This survey was sent out to and filled out by individual persons in the USA, aged 12 and over, the data was collected cross-sectionally. The survey collectors warn that this data is dependent on respondent’s truthfulness and memory, and should thus be taken with a grain of salt. Also, this survey does not include data from citizens who are active-duty military members or living in institutional group shelters (homeless shelters, hospitals, prisons, etc.). They warn that this may underestimate the use of certain drugs like heroin.\nFor the creation of the census, it was created by the United States Census Bureau Agency. It is done every 10 years and is a way to produce data on the American people and the economy of the United States as well. The hope in doing this is that the United States gets a better sense of how the American people are doing and where many people are located and understanding more about what kinds of decisions need to be made for the people or society. The census is conducted through electronic questionnaires to business, homes and many other places where someone may be. Sometimes they will sample people and conduct in person interviews as well but it is not possible to do it for every single person in America so relying on electronic questionnaires and other forms of filling the census are essential in the Bereau’s methods of collection.\n\n\n\nWhile we used the R file available to download to make the cleaned data set in our final project repository, we used the codebook to actually understand the data set R dataset file. The codebook contained information about each column and it was broken down into sections of self-administered substance abuse, imputed substance abuse, other self-administered sections, demographics, and geographic. We divided the sections and went through them, when sorting through the substance abuse sections, we stayed consistent in the types of columns we chose, those were: “age when first used”, “time since last used”, “number of days per week used in last 12 months”, and “best estimate of how many times used in last 30 days”.\nWhile the data set we are using from the 2021 NSDUH contains bountiful information concerning substance use, race, income, mental health, education, and age, it does not include very specific location information. The main information provided about the location of the survey respondents is stored in the variables “PDEN10” and “COUNTYP4”. This\n\n\n\nThis is the link to the script, cleaning script. The Script cleans the data by keeping only the columns that have enough responses to the questions and also are highly relevant questions that can be used in understanding the data. Our strategy is too use the columns with the most value in analysis. Questions like “Have you ever smoked a cigarette” have high response rates and gives key insight into how we can associate drug/substance use with what we are trying to look into. The script filtering involved taking all the questions we deemed qualified to be included in and the rest of the 2,800 variables in this dataset to be filtered out and to keep a consistent set of questions for the analysis use. Such selecting looks like:\ndrug_health_data_clean_new &lt;- PUF2021_100622 |&gt;\n  select(QUESTID2, filedate,\n         cigever, cigage, mjever, mjage, alcever, cocever, cocage, crkever, crkage, herever, herage, UD5ILLANY, ... (other variables)\nThen we save the dataframe into a rds file for storage purposes and continue to the other datasets.\nThe cleaning for the census dataset goes\nTo clean the CBSA data set, the readxl package was used to read the CBSA excel file. The data was already pretty clean, but in the original file there was a blank row and a few header rows, so we had to make sure to skip those. Then the columns were labeled and any missing values were converted to read as NA. A similar procedure was followed to read in an excel file containing Census data. With the Census data, we were interested in county populations by state. One thing we had to consider with the Census data was that it contained a row at the start of each state where the county name and the state name were the same and this row listed the state’s total population. While we did not remove this row when cleaning the data set, we were aware of it and would filter it out if necessary. For example, it was not necessary to filter out this row when we created a merged CBSA/CENSUS dataset since we joined the datasets on the conditions that a pair of state and county names matched in both datasets and since the CBSA data did not have any such pairs, it would automatically be eliminated.\nOne important thing that we had to look into when cleaning the CBSA and CENSUS data sets was the column types. We tried using the character() function to tell us the types of columns we were dealing with to pass into the read_excel() function. However, we still ran into parsing errors because the excel files had numeric values stored as texts. To address this issue, we used a feature of read_excel() that allowed us to pass in a column type “guess”, allowing R to guess at/decide on how it wanted to read in the numeric values stored as text which fixed the error message and produced readable data. Once this error had been fixed, we were able to save the cleaned CBSA and Census data sets as RDS files. To support our location information data, we also read in an excel dataset containing rural urban continuum codes which was then saved as an RDS file. This data set was easy enough to clean and we employed the same techniques as those mentioned for the Census and CBSA data sets."
  },
  {
    "objectID": "data.html#rubric-on-this-page",
    "href": "data.html#rubric-on-this-page",
    "title": "Data",
    "section": "Rubric: On this page",
    "text": "Rubric: On this page\nYou will\n\nDescribe where/how to find data.\n\nYou must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\nWhy was the data collected/curated? Who put it together? (This is important, if you don’t know why it was collected then that might not be a good dataset to look at.\n\nDescribe the different data files used and what each variable means.\n\nIf you have many variables then only describe the most relevant ones and summarize the rest.\n\nDescribe any cleaning you had to do for your data.\n\nYou must include a link to your load_and_clean_data.R file.\nAlso, describe any additional R packages you used outside of those covered in class.\nDescribe and show code for how you combined multiple data files and any cleaning that was necessary for that.\nSome repetition of what you do in your load_and_clean_data.R file is fine and encouraged if it helps explain what you did.\n\nOrganization, clarity, cleanliness of the page\n\nMake sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\nThis page should be self-contained."
  }
]